batch_size: 64

learning_rate: 1

num_epochs: 2

dropout: 0.25

weight_decay: 0.005