batch_size: 64

learning_rate: 0.01

num_epochs: 5

dropout: 0.25

weight_decay: 0.005